Self Driving Cars

In this technology rat race that we are creating, there are many ethical scenarios we have to consider. In semi-autonomous vehicles, instead of looking at the amount of lives that will be saved according to our predictions, we need to also look at the lives that'll be lost. Who'd be held responsible when an accident occurs especially in a scenario where the vehicle is programmed to go for the smallest thing when that could be a child. When a human is behind the wheel, someone who is capable of making split second decisions is in control, but a semi-autonomous vehicle has to be programmed in advance which means it has to have the data already available in order to react appropriately. We failed to realize that as much as a large amount of accidents were caused by human error, the self-driving cars are programmed by humans which leaves us at the mercy of the programmer who programmed a certain vehicle. We have seen cars been recalled due to computers malfunctioning and causing catastrophic damages in some scenarios. We still have to consider many ethical areas instead of focusing on the prediction that accidents will be reduced.
